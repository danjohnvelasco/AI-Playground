{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network From Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Gf893Nl30eUZ",
        "l6LjjQCm3-4D",
        "2CgWw_O097BX",
        "d_243F5bBe2E",
        "wjV42SkQr7zp",
        "y6KJcDwBA63P"
      ],
      "toc_visible": true,
      "mount_file_id": "1hFnCO-gp1AKJnU3dl1qquXIuiag0Quya",
      "authorship_tag": "ABX9TyM4R3tCOpe0UvXPUdWkon2N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danjohnvelasco/AI-Sandbox/blob/master/Neural_Network_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY-_0mZqzcLO"
      },
      "source": [
        "# Neural Network from Scratch\n",
        "\n",
        "My attempt in learning the concept of neural networks from ground up.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbSXyPQQncPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08957d3-c76d-447f-c6ec-f0c20207a5ce"
      },
      "source": [
        "!pip show fastai"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: fastai\n",
            "Version: 1.0.61\n",
            "Summary: fastai makes deep learning with PyTorch faster, more accurate, and easier\n",
            "Home-page: https://github.com/fastai/fastai\n",
            "Author: Jeremy Howard\n",
            "Author-email: info@fast.ai\n",
            "License: Apache Software License 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: pandas, pyyaml, nvidia-ml-py3, numexpr, numpy, bottleneck, dataclasses, beautifulsoup4, Pillow, fastprogress, packaging, requests, torchvision, torch, spacy, scipy, matplotlib\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRhbLGOpyD_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8993fe2d-6c73-45af-fe01-32a93fd3d003"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec 16 01:21:55 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKCWKvz4y1YW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76dc0d05-000e-4b66-c992-220df7b20e00"
      },
      "source": [
        "# autoreloads all modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWvrb2LzvCwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4cad788-efcc-4b59-aaee-5b78849e0fe3"
      },
      "source": [
        "proj_path = '/content/drive/My Drive/fastai/part2'\n",
        "%cd {proj_path}"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/fastai/part2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU7bB4zDwjyC"
      },
      "source": [
        "from test import *\n",
        "from mnist import *\n",
        "from matmul import *"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqXAPDBAw_Fp"
      },
      "source": [
        "# Demo importing and using python module\n",
        "test_eq(\"HELLO\", 'HELLO')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG1lh8qExCy4"
      },
      "source": [
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf893Nl30eUZ"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpWWNMJ9zvyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef75615a-d602-41ec-b3aa-65a9defc8ae6"
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = load_mnist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Status: Pass\n",
            "Data loaded successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkgZ2VRs03T7"
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3unwzLy3MjV"
      },
      "source": [
        "img = x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf3Gx5eK3Ow1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81e4a56-f816-4550-834b-65438c33b6a9"
      },
      "source": [
        "img.view(28,28).type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzL6YhB43P5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefce23a-e5f0-445d-97df-22014b1a414f"
      },
      "source": [
        "plt.imshow(img.view((28,28)));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAhE5BQP9DSp"
      },
      "source": [
        "weights = torch.randn(784,10) # 784 refers to mnist, 10 refers to number of activations (digits 0-9)\n",
        "bias = torch.zeros(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmMG_0Tm86xH"
      },
      "source": [
        "m1 = x_valid[:5]\n",
        "m2 = weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKwNDh0Z9A04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d059745f-14c2-433f-dc3a-b04d344bd1c1"
      },
      "source": [
        "# confirm shape\n",
        "m1.shape, m2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6LjjQCm3-4D"
      },
      "source": [
        "## Matrix Multipication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx4bF6SB3h7y"
      },
      "source": [
        "from matmul import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFpfAwJR9Piw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa200916-23a5-4e50-cf88-a012fa682f21"
      },
      "source": [
        "# result should have dimension 5 x 10\n",
        "# this is slow\n",
        "%time t1 = matmul_basic(m1, m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 841 ms, sys: 0 ns, total: 841 ms\n",
            "Wall time: 845 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq6yjaar9TXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d6bacd-3bd3-4803-cd90-7e7b8173abda"
      },
      "source": [
        "# The result is correct\n",
        "t1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CgWw_O097BX"
      },
      "source": [
        "## Elementwise operations\n",
        "\n",
        "Refactor your matmul loop to utilize elementwise vector operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_yUVSjk_tS3"
      },
      "source": [
        "from matmul import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wClA6Sg_g4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8392e350-e99f-4a21-ec21-0f33431d198e"
      },
      "source": [
        "m1 = x_valid[:5]\n",
        "m2 = weights\n",
        "\n",
        "# confirm shape\n",
        "m1.shape, m2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n86eKWl39qnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363a0a59-dbf1-4245-f40d-e12481d87dd0"
      },
      "source": [
        "# It's now ~10x faster because we're using\n",
        "# elementwise vector operations written in pytorch\n",
        "# which is probably not written in python\n",
        "%time t1 = matmul_el(m1, m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.76 ms, sys: 0 ns, total: 1.76 ms\n",
            "Wall time: 1.78 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1dhwsgt_ii4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c566b2e-a023-4903-8894-92e8ff72b9fa"
      },
      "source": [
        "# The result is correct\n",
        "t1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8DuQPLY_wqP"
      },
      "source": [
        "test_near(matmul(m1,m2), matmul_el(m1,m2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT35MODLAjXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb93d9b-4d4f-4b12-f333-44cabebeb19f"
      },
      "source": [
        "# Both matmul are identical\n",
        "matmul(m1,m2)[0], matmul_el(m1,m2)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ -9.8819, -18.7256, -17.7464,  -7.4682,  -0.6600,  -3.2809,  -4.9012,\n",
              "          -9.8645,   5.9814,   0.4755]),\n",
              " tensor([ -9.8819, -18.7256, -17.7464,  -7.4682,  -0.6600,  -3.2809,  -4.9012,\n",
              "          -9.8645,   5.9814,   0.4755]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_243F5bBe2E"
      },
      "source": [
        "## Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj_qNNlaBf_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a169f7a-e30e-475d-eae7-bdf47f5c75c4"
      },
      "source": [
        "# Toy small data to visualize the algorithm\n",
        "a = torch.rand(3, 3)\n",
        "b = torch.rand(3, 2)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5207, 0.1138, 0.8574],\n",
            "        [0.2467, 0.3023, 0.0629],\n",
            "        [0.9243, 0.3711, 0.2248]])\n",
            "tensor([[0.1439, 0.3608],\n",
            "        [0.5772, 0.2038],\n",
            "        [0.7731, 0.7944]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I6KwhgmkBPF",
        "outputId": "5d6c9323-78ee-42e1-95c2-890b06dcb30a"
      },
      "source": [
        "m1 = x_valid[:5]\n",
        "m2 = weights\n",
        "\n",
        "# confirm shape\n",
        "m1.shape, m2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaXkuJvQh3I1"
      },
      "source": [
        "from matmul import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY1LEaB-kD-e",
        "outputId": "369c826f-dfe2-443f-becb-0dcbf5d973cd"
      },
      "source": [
        "# Runtime now in µs, previously in ms\n",
        "%time t1 = matmul_br(m1, m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 550 µs, sys: 0 ns, total: 550 µs\n",
            "Wall time: 555 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEilyMVwkMzl",
        "outputId": "8223402e-c185-49b4-a668-8040a32a555a"
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JvAGTdekQ-Q"
      },
      "source": [
        "test_near(matmul_el(m1,m2), matmul_br(m1,m2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjV42SkQr7zp"
      },
      "source": [
        "## Einstein Summation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fknsumier6uc"
      },
      "source": [
        "from matmul import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dLpZSP-6H6N",
        "outputId": "6a0572f6-dbc7-4db9-bbd9-cb85f663d82d"
      },
      "source": [
        "# Much faster than broadcasting version\n",
        "%time t1 = matmul_einsum(m1, m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 184 µs, sys: 45 µs, total: 229 µs\n",
            "Wall time: 234 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqG-IvJL9gcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bd568d-ed10-44a2-bc1a-664e721c96f7"
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfr4Fz42AsOS"
      },
      "source": [
        "test_near(matmul_el(m1,m2), matmul_einsum(m1,m2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6KJcDwBA63P"
      },
      "source": [
        "## Default pytorch matmul (fastest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py8EPvw21M3E"
      },
      "source": [
        "from matmul import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6S8I8UhA9fl",
        "outputId": "6e5600fa-8293-4b43-a258-adc8cb2b0848"
      },
      "source": [
        "# Fastest\n",
        "%time t1 = matmul_fastest(m1,m2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 93 µs, sys: 23 µs, total: 116 µs\n",
            "Wall time: 120 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0RYuYA3BCPA",
        "outputId": "ad10f05c-26ed-4a38-f4fc-1c5248d7daa4"
      },
      "source": [
        "# Uses pytorch matmul when operands are pytorch tensors\n",
        "%time t2 = m1@m2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 133 µs, sys: 0 ns, total: 133 µs\n",
            "Wall time: 137 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewO-h3TLBYQu"
      },
      "source": [
        "test_near(t1, t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8cwRz0r77KW"
      },
      "source": [
        "# linear layer w/ bias\n",
        "t2 = linear(x=m1,w=m2,b=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KztxUBTT73ru"
      },
      "source": [
        "# Check if linear function is working correctly\n",
        "test_near(t1, t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdYTXFFT1dap"
      },
      "source": [
        "## Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2QO29qxERxp"
      },
      "source": [
        "from matmul import *\n",
        "from activations import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0ct9d7fC6kb"
      },
      "source": [
        "### Get Data and Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHIn48rfLXhH"
      },
      "source": [
        "Normalization typically means rescales the values into a range of [0,1]. Standardization typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance).\r\n",
        "[[Source]](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)\r\n",
        "\r\n",
        "Sometimes the terms are used interchangeably pero iba talaga ibig sabihin. Parang sa lesson na to, normalization tawag nila sa standardization.\r\n",
        "\r\n",
        "**Formula:**\r\n",
        "\r\n",
        "z = x - mean / stdev\r\n",
        "\r\n",
        "where z is the standardized value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF0_orC_CkSs",
        "outputId": "68917873-e268-4839-a05c-cb959746a7be"
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = load_mnist()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Status: Pass\n",
            "Data loaded successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR5u6ahLClfT",
        "outputId": "c6c464ce-4da7-4138-d60e-5a355a1540a6"
      },
      "source": [
        "x_train.mean(), x_train.std(), x_valid.mean(), x_valid.std()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073), tensor(0.1287), tensor(0.3050))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKSBnHXD9bqs"
      },
      "source": [
        "def normalize(x, m, s): \n",
        "    return (x-m)/s"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RhJEz_e9d9U",
        "outputId": "8047a5d3-99d3-4990-ef0c-fd5ef54dec26"
      },
      "source": [
        "# We must standardize our input first\n",
        "# To standardize, you must (x - mean)/std\n",
        "\n",
        "# Get the mean and std\n",
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yH-N_xj-wRu"
      },
      "source": [
        "# standardize train set\n",
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "\n",
        "# standardize validation set\n",
        "# Note: Use train set mean, not validation mean kasi magkaiba yan ng distribution\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI8wjAllCw-o",
        "outputId": "154830ef-74c6-435a-c286-dbde82294762"
      },
      "source": [
        "# Standardization should turn mean = 0, std = 1\n",
        "x_train.mean(), x_train.std(), x_valid.mean(), x_valid.std()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.8966e-08), tensor(1.), tensor(-0.0059), tensor(0.9924))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmdx34R2L4pw",
        "outputId": "5b260a74-fd8b-4250-a768-f88ddd34ae07"
      },
      "source": [
        "# Value is not rescaled between 0 and 1 which shows\r\n",
        "# that this is not the same as normalization\r\n",
        "x_train.min(), x_train.max()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.4245), tensor(2.8170))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uqgL51y2Jjg"
      },
      "source": [
        "### Defining basic architecture\n",
        "\n",
        "Here, we'll use Mean Squared Error (MSE) as a loss function to keep things simple. That's why you'll see that the output is of size **1**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uid-MEZG1ecu"
      },
      "source": [
        "# num of hidden units\n",
        "nh = 50\n",
        "\n",
        "# length of input (flattened 28 x 28 img)\n",
        "m = 784\n",
        "\n",
        "n = 50,000\n",
        "c = tensor(10)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0Xq6aj83Nj4",
        "outputId": "697ccfa4-5830-4932-a53e-0ed0787fea9b"
      },
      "source": [
        "# naive random init\n",
        "w1 = torch.randn(m,nh)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)\n",
        "b2 = torch.zeros(1)\n",
        "\n",
        "w1.mean(), w1.std()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0003), tensor(0.9932))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75TdxI5cDXNA",
        "outputId": "0ff073fd-e666-49a7-b6f3-4c84e6eef256"
      },
      "source": [
        "# Input has mean=0, std=1\n",
        "x_valid.mean(), x_valid.std()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0059), tensor(0.9924))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8cf8BLRFQqh"
      },
      "source": [
        "The result doesn't have a mean=0, std=1\n",
        "\n",
        "What we want is to have those properties in the activations\n",
        "\n",
        "Why? We'll know in the following lectures. (AUTHOR, ANSWER THIS LATER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nphni75TDP8X",
        "outputId": "4ad56441-d0a1-48d6-82de-8c7c318ee68f"
      },
      "source": [
        "t1 = linear(x_valid, w1, b1)\n",
        "t1.mean(), t1.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1957), tensor(25.9628))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOV7xSXY3I7x",
        "outputId": "228fa75e-ac77-4a19-d643-68afecbdecb8"
      },
      "source": [
        "# standard xavier init\n",
        "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)\n",
        "\n",
        "w1.mean(), w1.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(8.6533e-05), tensor(0.0357))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVCvlh0OFUkl"
      },
      "source": [
        "Using xavier init, the activations have mean=0, std=1 (or at least, close to it)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UsB8tjm7no-",
        "outputId": "09c0c5d9-3b54-4df3-f2dc-f92ae93c20e9"
      },
      "source": [
        "t1 = linear(x_valid, w1, b1)\n",
        "t1.mean(), t1.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0810), tensor(1.0039))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cpaxgUXFXDP"
      },
      "source": [
        "But after a relu, it's gone...\n",
        "\n",
        "Why? Because RELU gets rid of the negatives that is why the mean is almost halved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7mkUT-sD5zu",
        "outputId": "e464ebf8-a697-444b-e247-2ff94413fa90"
      },
      "source": [
        "t1 = relu(linear(x_valid, w1, b1))\n",
        "t1.mean(), t1.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3562), tensor(0.5635))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq4v_vK3FOSl"
      },
      "source": [
        "**This is where kaiming init comes to the rescue!**\n",
        "\n",
        "Standard deviation will halve every layer which means that there is not much left after a couple of layers. We solve this problem by dividing 2 with m.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "math.sqrt(2/m)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-dLFiFhEOvT",
        "outputId": "d7384e7a-f480-4977-f267-db233b74b680"
      },
      "source": [
        "# kaiming init\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)*math.sqrt(2/nh)\n",
        "b2 = torch.zeros(1)\n",
        "\n",
        "w1.mean(), w1.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0002), tensor(0.0505))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Ejf6MMF3uM"
      },
      "source": [
        "The standard deviation should now be closer to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbi6onJOF0Ah",
        "outputId": "90510770-b26d-485e-ea47-e3835c05dbed"
      },
      "source": [
        "t1 = relu(linear(x_valid, w1, b1))\n",
        "t1.mean(), t1.std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5217), tensor(0.8159))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOSTBVgtF-GV"
      },
      "source": [
        "One slight problem though, the mean is still not closer to 0.\n",
        "\n",
        "So Jeremy Howard thought, why not subtract 0.5 from the relu function?\n",
        "\n",
        "\n",
        "```\n",
        "def relu(x): return x.clamp_min(0.) - 0.5\n",
        "```\n",
        "\n",
        "Let's see how it goes...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhkU-7w0F1Az"
      },
      "source": [
        "def relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD1H267WGr4d"
      },
      "source": [
        "This should show that the mean is closer to 0 now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0U7u_LoGpKx",
        "outputId": "e6d4c92b-c506-41e9-aaa3-6fc457a901cd"
      },
      "source": [
        "t1 = relu(linear(x_valid, w1, b1))\n",
        "t1.mean(), t1.std()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(10.9083), tensor(16.1153))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ollw-fRsGxD5"
      },
      "source": [
        "At this point, I still don't get it why subtract 0.5 from the relu. What's happening here is that instead of removing the negatives, we replace all negatives with -0.5. See the following cells.\n",
        "\n",
        "**I still don't know why it's so important to keep the mean closer to 0 and std closer to 1, but we'll find out in the upcoming lectures. Right now, we're at Lesson 8.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfKfH6f5HFew",
        "outputId": "5785bcee-1e87-45c2-842b-682aee90d845"
      },
      "source": [
        "t1.min(), t1.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.5000), tensor(6.5514))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "eyTbJIYoHLIe",
        "outputId": "07d410e5-2580-4fba-8537-639bdcc8dbd2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(t1[0].numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f87cd7306a0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbrQF-DBImAW"
      },
      "source": [
        "At this point, we now have linear layer (matrix multiplication), activation function (ReLU), decent network normalization (or more accurately, standardization), and initialization (kaiming init) so we can now do a **Forward Pass**.\r\n",
        "\r\n",
        "All of these are implemented in PyTorch so let's use that instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWyg8RY_Jx5"
      },
      "source": [
        "from torch.nn import init\r\n",
        "\r\n",
        "# initialize tensors\r\n",
        "w1 = torch.zeros(m,nh)\r\n",
        "b1 = torch.zeros(nh)\r\n",
        "\r\n",
        "# perform kaiming initialization\r\n",
        "# fan_out means we divide by nh in kaiming init which means the variance is \r\n",
        "# 1 (or closer to 1) during the backward pass. Note: Implementation details \r\n",
        "# nalang ito at hindi ganoon ka related sa concepts\r\n",
        "init.kaiming_normal_(w1, mode='fan_out')\r\n",
        "t = relu(linear(x_valid, w1, b1))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzAIhHnjKeYB"
      },
      "source": [
        "### Doing a Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O192AOOGqRz"
      },
      "source": [
        "def model(xb):\n",
        "    # kaiming init\n",
        "    w1 = torch.randn(m,nh)*math.sqrt(2/m)\n",
        "    b1 = torch.zeros(nh)\n",
        "    w2 = torch.randn(nh,1)*math.sqrt(2/nh)\n",
        "    b2 = torch.zeros(1)\n",
        "\n",
        "    # architecture\n",
        "    i_h = relu(linear(xb, w1, b1)) # input to hidden\n",
        "    h_o = linear(i_h, w2, b2) # hidden to output\n",
        "\n",
        "    return h_o"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ4i6bMyKxug"
      },
      "source": [
        "t1=model(x_train)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk45zw0vK3SX",
        "outputId": "e92eb806-2a27-4595-cc16-e6e1a5344db6"
      },
      "source": [
        "# Should be 50,0000 x 1\n",
        "t1.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqRAGq73R90r"
      },
      "source": [
        "### Short review for torch.unsqueeze and squeeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1EpKC2FQUmZ",
        "outputId": "5c5ea4aa-93d7-4826-a281-ec359e2b670d"
      },
      "source": [
        "x = torch.tensor([1, 2, 3, 4])\r\n",
        "x.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAM7IZxoRUfd",
        "outputId": "ae01001c-f877-4f6b-c1c5-aadbea9a7814"
      },
      "source": [
        "# Add dimension of size one to the left\r\n",
        "torch.unsqueeze(x, 0).size()\r\n",
        "\r\n",
        "# Add dimension of size one to the right\r\n",
        "torch.unsqueeze(x, 1).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 4]), torch.Size([4, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PScJq5kGRZbL",
        "outputId": "bf83e269-0fa4-4dba-829f-2725feca33e0"
      },
      "source": [
        "y = torch.unsqueeze(x, 1)\r\n",
        "z = torch.unsqueeze(y, 0)\r\n",
        "z.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHxrQ4lISd1X",
        "outputId": "43c26480-11d9-4d17-886a-1e078ed5df82"
      },
      "source": [
        "z.squeeze().size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0dxG3iCTHzB",
        "outputId": "31ee7260-8d9a-42e2-a25f-85bfb6022af6"
      },
      "source": [
        "# Remove\r\n",
        "a = torch.unsqueeze(x, 1)\r\n",
        "a.size(), a.squeeze(-1).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 1]), torch.Size([4]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAt27U4ySDde"
      },
      "source": [
        "### Loss function: MSE\r\n",
        "\r\n",
        "#### $MSE = \\frac{1}{n}\\sum_{i=1}^{n} (y_{i}-\\hat{y}_{i})^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMX6kzR0SHst"
      },
      "source": [
        "def mse(output, targ):\r\n",
        "    # We need to get rid of the trailing (,1) dimension of i_h ([50000,1])\r\n",
        "    # to get MSE to work\r\n",
        "    return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB0WskuIT2to"
      },
      "source": [
        "y_train,y_valid = y_train.float(),y_valid.float()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VNT_ZgPT8M0"
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3eh64m3T8wr",
        "outputId": "aff278cf-bf07-4cd8-f5f5-826ae68500bd"
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJd6krZqT_Do",
        "outputId": "beeed31d-b2ff-4d47-fab8-96968f3bea5b"
      },
      "source": [
        "mse(preds, y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(33.2137)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cIjjVwzUa3a"
      },
      "source": [
        "## Gradients and backward pass\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db0oi4LpLRMn"
      },
      "source": [
        "We'll calculate the gradients starting from the very last function back to the\r\n",
        "very first function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHVLwxawvGCs"
      },
      "source": [
        "### For calculating gradient of the loss function w.r.t. to the output of previous layer\r\n",
        "\r\n",
        "Recall that $MSE = \\frac{1}{n}\\sum_{i=1}^{n} (y_{i}-\\hat{y}_{i})^{2}$ where $y$ is the output of previous layer.\r\n",
        "\r\n",
        "Take the $\\frac{\\partial }{\\partial y}$\r\n",
        "\r\n",
        "We can ignore the $\\sum$ for now and focus on $\\frac{1}{n} (y_{i}-\\hat{y}_{i})^{2}$\r\n",
        "\r\n",
        "By chain rule:\r\n",
        "\r\n",
        "$\\frac{\\partial f}{\\partial y} = \\frac{2}{n} (y_{i}-\\hat{y}_{i})*1-0$\r\n",
        "\r\n",
        "\r\n",
        "**Final answer:**\r\n",
        "\r\n",
        "$\\frac{\\partial f}{\\partial y} = \\frac{2}{n} (y_{i}-\\hat{y}_{i})$\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NwNEvEpqaAt",
        "outputId": "c340e69e-70bc-4ebe-d3e4-bfdce8c0a313"
      },
      "source": [
        "# let's take a look at the dimension of the model's output\r\n",
        "# this is mse_grad's inp parameter\r\n",
        "t1=model(x_train)\r\n",
        "t1.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrDpbRQuqnki",
        "outputId": "cc96309b-0247-4ec3-beef-3728d672165c"
      },
      "source": [
        "# let's take a look at the dimension of the gold labels\r\n",
        "# this is mse_grad's targ parameter\r\n",
        "y_train.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxitmiD2qHXf"
      },
      "source": [
        "def mse_grad(inp, targ):\r\n",
        "    # the inp is the output of the previous layer\r\n",
        "    # inp and targ must have the same dimension to do arithmetic operations\r\n",
        "    # reduce the dimension of inp to match targ's dimension\r\n",
        "    # take the gradient\r\n",
        "    # return it to rank 2 tensor\r\n",
        "    # store it in the inp\r\n",
        "    # by storing it in the inp, the previous layer can access it. Why?\r\n",
        "    # think backwards\r\n",
        "    inp.g = 2 * (inp.squeeze(-1) - targ).unsqueeze(-1) / inp.shape[0]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRLHtm3Ky2-u"
      },
      "source": [
        "### For calculating the gradient of ReLU\r\n",
        "\r\n",
        "Recall that ReLU replaces the negatives with 0 and retains all positives which gives us a straigh line (y=x) on the 1st quadrant and flat line at the negative x-axis.\r\n",
        "\r\n",
        "In other words:\r\n",
        "\r\n",
        "         f(x) = 0 if x < 0\r\n",
        "                x if x >= 0  \r\n",
        "\r\n",
        "Calculating the gradient:\r\n",
        "\r\n",
        "         f'(x) = 0 if x < 0\r\n",
        "                 1 if x >= 0  \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTFqOUd1ywXs"
      },
      "source": [
        "def relu_grad(inp, out):\r\n",
        "    # you can access the mse_grad from out param\r\n",
        "    # multiply the gradient of loss function i.e. the next layer\r\n",
        "    # to the derivative of the ReLU\r\n",
        "    inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LJWdEAM9Ngs"
      },
      "source": [
        "### For calculating the gradient of linear layer (matrix multiplication)\r\n",
        "\r\n",
        "Recall that linear is just x @ w + b. Where @ is matrix multiplication, x = input, w = weights, and b = bias.\r\n",
        "\r\n",
        "####To use chain rule for the dot product\r\n",
        "Recall that a dot product is the same as doing element-wise multiplication and then summing it up ($ sum(x {\\otimes} w) $).\r\n",
        "\r\n",
        "To break it down into components: \r\n",
        "\r\n",
        "$\\vec{u} = \\vec{x} {\\otimes} \\vec{w}$\r\n",
        "\r\n",
        "$v = sum(\\vec{u}))$\r\n",
        "\r\n",
        "$y = v + b$\r\n",
        "\r\n",
        "If you substitute them all together it gives:\r\n",
        "\r\n",
        "$y = sum(x {\\otimes} w) + b$\r\n",
        "\r\n",
        "which is similar to this:\r\n",
        "\r\n",
        "$y = \\ x {\\cdot}  w + b $\r\n",
        "\r\n",
        "**The gradient of matmul w.r.t. to input:**\r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial \\vec{x}} = \\frac{\\partial}{\\partial \\vec{x}} sum(x {\\otimes} w) + \\frac{\\partial}{\\partial \\vec{x}} b$\r\n",
        "\r\n",
        "Let's focus on  $\\frac{\\partial}{\\partial \\vec{x}} sum(x {\\otimes} w)$:\r\n",
        "\r\n",
        "Since we know that $\\vec{u} = \\vec{x} {\\otimes} \\vec{w}$, $v = sum(\\vec{u}))$\r\n",
        ", and $y = v + b$, then...\r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial \\vec{x}} = \\frac{\\partial y}{\\partial v} \\frac{\\partial v}{\\partial \\vec{u}} \\frac{\\partial \\vec{u}}{\\partial \\vec{x}}$\r\n",
        "\r\n",
        "$\\frac{\\partial \\vec{u}}{\\partial \\vec{x}} = diag(w)$ ; diagonal matrix\r\n",
        "\r\n",
        "$\\frac{\\partial v}{\\partial \\vec{u}} = \\vec{1}^{T}$ ; just a horizontal vector of 1's\r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial v} = 1 + 0$\r\n",
        "\r\n",
        "Therefore,\r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial x} = 1 * \\vec{1} * w$ ; e.g. 1 x 3 * 3 x 3 = 1 x 3 yung diagonal matrix naging horizontal vector lang.\r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial x} = w^{T}$ ; so yung mga weights na transpose lang (naging horizontal vector) pero matrix padin in practice kasi by batch siya i-process. Math-wise, you can treat them as a single instance represented in a vector.\r\n",
        "\r\n",
        "\r\n",
        "**The gradient of matmul w.r.t. to weights:**\r\n",
        "\r\n",
        "Similar to computation above...\r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial \\vec{w}} = \\frac{\\partial}{\\partial \\vec{w}} sum(x {\\otimes} w) + \\frac{\\partial}{\\partial \\vec{w}} b$\r\n",
        "\r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial \\vec{x}} = \\frac{\\partial y}{\\partial v} \\frac{\\partial v}{\\partial \\vec{u}} \\frac{\\partial \\vec{u}}{\\partial \\vec{x}}$\r\n",
        "\r\n",
        "$\\frac{\\partial \\vec{u}}{\\partial \\vec{w}} = diag(x)$ ; diagonal matrix\r\n",
        "\r\n",
        "$\\frac{\\partial v}{\\partial \\vec{u}} = \\vec{1}^{T}$ \r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial v} = 1 + 0$\r\n",
        "\r\n",
        "Therefore,\r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial x} = 1 * \\vec{1} * x$ \r\n",
        "\r\n",
        "$\\frac{\\partial y}{\\partial x} = x^{T}$ \r\n",
        "\r\n",
        "**The gradient of matmul w.r.t. to bias:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNfB7mRu52X4"
      },
      "source": [
        "def lin_grad(inp, out, w, b):\r\n",
        "    # inp : output of previous layer\r\n",
        "    # out : out.g is gradient of next layer\r\n",
        "    # w   : weights\r\n",
        "    # b   : bias\r\n",
        "    \r\n",
        "    # grad wrt to input is just weights transpose\r\n",
        "    inp.g = out.g @ w.t()       # grad of next layer * grad of this layer\r\n",
        "\r\n",
        "    # grad wrt to w is just the inputs\r\n",
        "    w.g =  (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0) # sum(input * grad of next layer); may sum dahil sa cost function MSE ay may summation (which is inignore natin kanina)\r\n",
        "\r\n",
        "    # grad wrt to b is just vector of 1's\r\n",
        "    b.g = out.g.sum(0) # sum(1 * grad of next layer); again, may sum dahil sa MSE"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz4pOxJ0QCg3"
      },
      "source": [
        "def forward_and_backward(inp, targ):\r\n",
        "    # forward pass:\r\n",
        "    l1 = inp @ w1 + b1\r\n",
        "    l2 = relu(l1)\r\n",
        "    out = l2 @ w2 + b2\r\n",
        "\r\n",
        "    # Hindi ginagamit ang loss (scalar) per se sa computation ng gradients. Para lang siya sa tao.\r\n",
        "    # Hindi siya ginagamit in a sense na kahit tanggalin ko tong line of code na to, magagawa padin ang backpropagation\r\n",
        "    loss = mse(out, targ)\r\n",
        "\r\n",
        "    # backward pass\r\n",
        "    # chain rule lang from loss function to first layer (not including data input)\r\n",
        "    # na iniistore yung gradients at pinapasa pabalik (backwards)\r\n",
        "    mse_grad(out, targ)\r\n",
        "    lin_grad(l2, out, w2, b2)\r\n",
        "    relu_grad(l1, l2)\r\n",
        "    lin_grad(inp, l1, w1, b1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tGoTiXzShFR"
      },
      "source": [
        "def model(inp, targ):\r\n",
        "    # forward pass:\r\n",
        "    l1 = inp @ w1 + b1\r\n",
        "    l2 = relu(l1)\r\n",
        "    out = l2 @ w2 + b2\r\n",
        "\r\n",
        "    # Hindi ginagamit ang loss (scalar) per se sa computation ng gradients. Para lang siya sa tao.\r\n",
        "    # Hindi siya ginagamit in a sense na kahit tanggalin ko tong line of code na to, magagawa padin ang backpropagation\r\n",
        "    loss = mse(out, targ)\r\n",
        "\r\n",
        "    # backward pass\r\n",
        "    # chain rule lang from loss function to first layer (not including data input)\r\n",
        "    # na iniistore yung gradients at pinapasa pabalik (backwards)\r\n",
        "    mse_grad(out, targ)\r\n",
        "    lin_grad(l2, out, w2, b2)\r\n",
        "    relu_grad(l1, l2)\r\n",
        "    lin_grad(inp, l1, w1, b1)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGOifgzIStac"
      },
      "source": [
        "# kaiming init\r\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)\r\n",
        "b1 = torch.zeros(nh)\r\n",
        "w2 = torch.randn(nh,1)*math.sqrt(2/nh)\r\n",
        "b2 = torch.zeros(1)\r\n",
        "\r\n",
        "model(x_train, y_train)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFDtx8nyS2s7"
      },
      "source": [
        "# Save for testing against later\r\n",
        "w1g = w1.g.clone()\r\n",
        "w2g = w2.g.clone()\r\n",
        "b1g = b1.g.clone()\r\n",
        "b2g = b2.g.clone()\r\n",
        "ig  = x_train.g.clone()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EZNmxR7TLyx"
      },
      "source": [
        "We use autograd to check if our results matches PyTorch's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HksFUurTPXa"
      },
      "source": [
        "xt2 = x_train.clone().requires_grad_(True)\r\n",
        "w12 = w1.clone().requires_grad_(True)\r\n",
        "w22 = w2.clone().requires_grad_(True)\r\n",
        "b12 = b1.clone().requires_grad_(True)\r\n",
        "b22 = b2.clone().requires_grad_(True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N8i6mSnTVek"
      },
      "source": [
        "def forward(inp, targ):\r\n",
        "    # forward pass:\r\n",
        "    l1 = inp @ w12 + b12\r\n",
        "    l2 = relu(l1)\r\n",
        "    out = l2 @ w22 + b22\r\n",
        "    # we don't actually need the loss in backward!\r\n",
        "    return mse(out, targ)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94v6TRshTYEk"
      },
      "source": [
        "loss = forward(xt2, y_train)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9OywAjTTavJ"
      },
      "source": [
        "# Computes the gradient of current tensor w.r.t. graph leaves\r\n",
        "loss.backward()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_T8_87uTiND"
      },
      "source": [
        "# Our gradients are almost the same as PyTorch's\r\n",
        "test_near(w22.grad, w2g)\r\n",
        "test_near(b22.grad, b2g)\r\n",
        "test_near(w12.grad, w1g)\r\n",
        "test_near(b12.grad, b1g)\r\n",
        "test_near(xt2.grad, ig)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH1FO3vhToMH",
        "outputId": "3976597e-a695-4ca0-f914-6b116039b88d"
      },
      "source": [
        "w2g, w22.grad"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.0160],\n",
              "         [ 3.1725],\n",
              "         [-0.0780],\n",
              "         [ 2.3847],\n",
              "         [-1.3138],\n",
              "         [-7.2877],\n",
              "         [ 0.0291],\n",
              "         [-0.9729],\n",
              "         [ 2.6821],\n",
              "         [ 1.9815],\n",
              "         [ 0.8676],\n",
              "         [-2.0644],\n",
              "         [-0.6822],\n",
              "         [-3.1738],\n",
              "         [-0.6303],\n",
              "         [-2.2340],\n",
              "         [ 3.6144],\n",
              "         [-2.9175],\n",
              "         [-3.8486],\n",
              "         [ 2.2971],\n",
              "         [ 0.5628],\n",
              "         [-0.5422],\n",
              "         [ 3.3900],\n",
              "         [-5.8169],\n",
              "         [-0.0593],\n",
              "         [-3.8683],\n",
              "         [ 1.2840],\n",
              "         [ 1.9721],\n",
              "         [-0.3568],\n",
              "         [-8.8591],\n",
              "         [ 1.5657],\n",
              "         [ 3.4140],\n",
              "         [-1.4701],\n",
              "         [-5.7629],\n",
              "         [-4.1701],\n",
              "         [ 3.2771],\n",
              "         [ 2.2940],\n",
              "         [ 3.0983],\n",
              "         [ 3.7652],\n",
              "         [-8.9139],\n",
              "         [-3.6991],\n",
              "         [ 1.4770],\n",
              "         [ 0.2276],\n",
              "         [ 3.3148],\n",
              "         [ 0.2902],\n",
              "         [ 3.5102],\n",
              "         [-1.3987],\n",
              "         [ 2.0827],\n",
              "         [ 1.6408],\n",
              "         [-1.1727]]), tensor([[ 0.0160],\n",
              "         [ 3.1725],\n",
              "         [-0.0780],\n",
              "         [ 2.3847],\n",
              "         [-1.3138],\n",
              "         [-7.2877],\n",
              "         [ 0.0291],\n",
              "         [-0.9729],\n",
              "         [ 2.6821],\n",
              "         [ 1.9815],\n",
              "         [ 0.8676],\n",
              "         [-2.0644],\n",
              "         [-0.6822],\n",
              "         [-3.1738],\n",
              "         [-0.6303],\n",
              "         [-2.2340],\n",
              "         [ 3.6144],\n",
              "         [-2.9175],\n",
              "         [-3.8485],\n",
              "         [ 2.2971],\n",
              "         [ 0.5628],\n",
              "         [-0.5422],\n",
              "         [ 3.3899],\n",
              "         [-5.8169],\n",
              "         [-0.0593],\n",
              "         [-3.8683],\n",
              "         [ 1.2840],\n",
              "         [ 1.9721],\n",
              "         [-0.3568],\n",
              "         [-8.8590],\n",
              "         [ 1.5657],\n",
              "         [ 3.4140],\n",
              "         [-1.4701],\n",
              "         [-5.7629],\n",
              "         [-4.1701],\n",
              "         [ 3.2771],\n",
              "         [ 2.2940],\n",
              "         [ 3.0984],\n",
              "         [ 3.7652],\n",
              "         [-8.9139],\n",
              "         [-3.6991],\n",
              "         [ 1.4770],\n",
              "         [ 0.2276],\n",
              "         [ 3.3148],\n",
              "         [ 0.2902],\n",
              "         [ 3.5102],\n",
              "         [-1.3987],\n",
              "         [ 2.0827],\n",
              "         [ 1.6408],\n",
              "         [-1.1727]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBS4ex4WUT5n"
      },
      "source": [
        "## Refactor everything\r\n",
        "\r\n",
        "Now that we've coded from scratch the essential pieces: matrix multiplication, kaiming initialization, activation (ReLU), loss (MSE), forward and backward pass, we can now refactor the code to make it usable.\r\n",
        "\r\n",
        "We can also now use PyTorch since we already know how the pieces work so it's not magical now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RqLutDDUWtv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}