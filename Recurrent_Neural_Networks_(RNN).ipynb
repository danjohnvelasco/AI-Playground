{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent Neural Networks (RNN).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3fEMF8oqqqNPkOjmORJrH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danjohnvelasco/AI-Playground/blob/master/Recurrent_Neural_Networks_(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w45E0cyJk_KS"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "\n",
        "Building a 3 layer neural network, refactoring it to become RNN, improving the RNN by adding states, etc...\n",
        "\n",
        "This is a way for me to understand RNNs deeply.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuOMuLedlJW-",
        "outputId": "706b99fa-e1e3-497c-894e-b84a0e3a683d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Nov  1 09:41:47 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8LEllVuk8-C"
      },
      "source": [
        "!pip install -U fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV33qFqwlKOC",
        "outputId": "301ac7fd-3c85-4409-cafc-23cefe0b6382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlv_jemFllmA",
        "outputId": "ed7defb4-b177-40ad-a299-6b340a51f20e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/human_numbers/valid.txt'),Path('/root/.fastai/data/human_numbers/train.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKUDOh0WmQmU",
        "outputId": "fcd19a59-81a3-4189-8c0e-1e83683c9289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Behaves like a list of `items` but can also index with list of indices or masks\n",
        "lines = L(1,2,5)\n",
        "lines[[0,2]] # You can't do this on a standard array"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [1,5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIggSjECmvtm",
        "outputId": "ea55c3e1-6649-4f2f-dfe9-425d73044086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lines = L()\n",
        "\n",
        "# concat two text files\n",
        "with open(path/'train.txt') as f: \n",
        "    lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: \n",
        "    lines += L(*f.readlines())\n",
        "\n",
        "lines"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn9f0UrZnSNJ",
        "outputId": "6fc876dc-6da3-402a-b40f-76eb280949c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# remove extra whitespaces and \\n from string\n",
        "# then concat each string item list into one big string\n",
        "text = ' . '.join([l.strip() for l in lines])\n",
        "text[:100]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CrPj8NQzENw",
        "outputId": "3620cd52-4083-4f5e-8bd3-3304ca06a7c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# tokenize the dataset by splitting on spaces\n",
        "tokens = text.split(' ')\n",
        "tokens[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEna_DFc0m-n"
      },
      "source": [
        "## Numericalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnUzZlMKzqUK",
        "outputId": "f1173f27-fce4-4b6c-ec85-ee2905c89886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create a list containing all unique items\n",
        "# me: why not just use sets? Answer: walang index ang sets (they are unordered)\n",
        "# but you can loop over it.\n",
        "vocab = L(*tokens).unique()\n",
        "vocab"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK3oXAkO0yLe",
        "outputId": "7cd848d6-2733-4ed1-e8a1-4e074a8c7c58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# example of enumerate\n",
        "# enumerate adds counter to an iterable (e.g. 0, \"whatever\") and returns as a \n",
        "# enumerate object. This is useful if you want to get the index of each element\n",
        "# such as numericalization\n",
        "for w,i in enumerate(vocab[:10]):\n",
        "    print(w,i)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 one\n",
            "1 .\n",
            "2 two\n",
            "3 three\n",
            "4 four\n",
            "5 five\n",
            "6 six\n",
            "7 seven\n",
            "8 eight\n",
            "9 nine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QOEvIMiz_06",
        "outputId": "eb1d2c09-f5d0-46d6-c70c-4abbf2bdbb0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Assign an index for each unique word\n",
        "word_to_index = {word:index for index, word in enumerate(vocab)}\n",
        "word_to_index"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 1,\n",
              " 'eight': 8,\n",
              " 'eighteen': 18,\n",
              " 'eighty': 26,\n",
              " 'eleven': 11,\n",
              " 'fifteen': 15,\n",
              " 'fifty': 23,\n",
              " 'five': 5,\n",
              " 'forty': 22,\n",
              " 'four': 4,\n",
              " 'fourteen': 14,\n",
              " 'hundred': 28,\n",
              " 'nine': 9,\n",
              " 'nineteen': 19,\n",
              " 'ninety': 27,\n",
              " 'one': 0,\n",
              " 'seven': 7,\n",
              " 'seventeen': 17,\n",
              " 'seventy': 25,\n",
              " 'six': 6,\n",
              " 'sixteen': 16,\n",
              " 'sixty': 24,\n",
              " 'ten': 10,\n",
              " 'thirteen': 13,\n",
              " 'thirty': 21,\n",
              " 'thousand': 29,\n",
              " 'three': 3,\n",
              " 'twelve': 12,\n",
              " 'twenty': 20,\n",
              " 'two': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGwtylJN1147",
        "outputId": "3a8c6a6a-98af-4392-e1d0-b3cdd1bf9362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Numericalize by feeding the tokens into the dictionary and converting \n",
        "# the strings into its corresponding index\n",
        "\n",
        "nums = L(word_to_index[i] for i in tokens)\n",
        "nums"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrUbu6fw2lEN"
      },
      "source": [
        "# Language Model from scratch\n",
        "\n",
        "neural network architecture that takes three words as input, and returns a prediction of the probability of each possible next word in the vocab\n",
        "\n",
        "Jargon: \n",
        "\n",
        "hidden state (h): The activations that are updated at each step of a recurrent neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D42VcFQE2nRw",
        "outputId": "394f8cda-db4e-454d-d0f3-ab02437f97cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create trigrams\n",
        "# input data are converted to tensors (for training)\n",
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4,3))\n",
        "seqs"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7QebGPa29Lr"
      },
      "source": [
        "bs = 32\n",
        "cut = int(len(seqs) * 0.8)\n",
        "train = seqs[:cut] # 80% of data\n",
        "test = seqs[cut:] # 20% of data\n",
        "dls = DataLoaders.from_dsets(train, test, bs=bs, shuffle=False) # create dataloader "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn5l0bVKOcQm",
        "outputId": "3669adc4-c916-4796-8818-3b5885112f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dls.dataset[0][1]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grr4DmVM3jvG"
      },
      "source": [
        "class LM1(Module): # Module is same as nn.Module but no need to call super().__init__\n",
        "    # i == input, h = hidden, o == output\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        # Embedding takes an index as input and outputs an embedding matrix\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden) # vocab_sz == how many words in a vocab. n_hidden, you decide how wide yung embeddings\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden) # Linear does this: y = xA^T + b, where A == weights, b = bias\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz) # outputs probability of each word in the vocab\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: bs x input cols (word in a trigram) kaya x[:,0] means all first word of each item in a batch size\n",
        "        # here, h is an activation\n",
        "        h = F.relu(self.h_h(self.i_h(x[:,0]))) # 1st word --> embedding --> linear --> non-linear; 64 x 64\n",
        "        h = h + self.i_h(x[:,1]) # 2nd word embedding added to activations of 1st word; 64 x 64 \n",
        "        h = F.relu(self.h_h(h))\n",
        "        h = h + self.i_h(x[:,2]) # 3rd word embedding added to activations of 1st and 2nd word; 64 x 64\n",
        "        h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi6OSdSq7Nzv",
        "outputId": "fa4258f5-4fd4-4b18-92a3-0e8f3facb6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "learn = Learner(dls, LM1(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.421474</td>\n",
              "      <td>1.829477</td>\n",
              "      <td>0.487045</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.224868</td>\n",
              "      <td>1.838881</td>\n",
              "      <td>0.483242</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.316173</td>\n",
              "      <td>1.558987</td>\n",
              "      <td>0.489185</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.312844</td>\n",
              "      <td>1.590017</td>\n",
              "      <td>0.503447</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KratUBoPNKnN"
      },
      "source": [
        "# RNN\n",
        "\n",
        "Just a refactored version (adding a for loop) of a fully connected neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmUxtoE77qXN"
      },
      "source": [
        "class LM2(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden) \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden) \n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        n = x.shape[1] # how wide is the input\n",
        "\n",
        "        for i in range(n): # n = 3 because it's a trigram\n",
        "            h = h + self.i_h(x[:,i]) # ith word --> embedding --> linear --> non-linear; 64 x 64\n",
        "            h = F.relu(self.h_h(h))\n",
        "            \n",
        "        return self.h_o(h)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm_W3kFdQfwN",
        "outputId": "311cee39-9da2-4f63-a56f-9ff6c7cc027c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "learn = Learner(dls, LM2(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.425016</td>\n",
              "      <td>1.924794</td>\n",
              "      <td>0.486808</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.218480</td>\n",
              "      <td>1.903235</td>\n",
              "      <td>0.485857</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.315840</td>\n",
              "      <td>1.655130</td>\n",
              "      <td>0.495603</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.320415</td>\n",
              "      <td>1.608845</td>\n",
              "      <td>0.499406</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HN0OrDIVH0g"
      },
      "source": [
        "# Improving RNN by maintaing the state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T60QKgTbQ5Ez"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}